
# 服务器散热进化史

### 液冷方案崛起
最近在关注美股，围观行业大佬分析NV 供应链体系，注意到一家公司VRT， 这家公司是NV 的独家液冷方案提供商。最近VRT 的股价青云直上，一家做液冷方案的公司护城河到底有多深，散热方案在整个行业中处于什么位置，这些问题是我想了解的。

NV 的技术路线图从A100/H100 到最新GB200 的体系，TDP 也从300~700W 跃升到1000W 的门槛，以往的风冷方案在散热效率上显得非常力不从心。从2019 年的数据来看，国内IDC 能耗43%用于 IT 设备散热， 基本与 45%的 IT 设备自身能耗持平，这在低碳的大背景下，与IDC 行业追求的PUE 小于1.3 相背离。
>全国数据中心 PUE 平均水平为 1.49，传统风冷数据中心 PUE 在 1.5~1.8（1kW 的服务器正常运转需 1.5~1.8kW 电量）

### 传统风冷
从目前所有可见的消息来看，提高目前IDC风冷方案散热效率都是大势所趋，液冷方案呼之欲出，想要部署密度极高机架（30kW以上）的设施在是否使用液冷方面几乎没有选择余地。无论如何配置或优化系统，风冷都无法提供维持IT系统可靠性所需的散热能力。在边缘计算和核心数据中心都是如此。我们先来看看液冷方案相比于风冷有哪些优势：
- 液体导热能力是空气的 25 倍，同体积液体带走热量是同体积空气的近 3000 倍，液冷技术可实现40~55℃高温供液，无需压缩机冷水机组，采用室外冷却塔，可实现全年自然冷却
- 在耗电量方面，液冷系统约比风冷系统节省电量 30~50%
- 生态环境的优势：液冷噪音低，能够降低冷却风机转速或者采用无风机设计，从而具备极佳的降噪效果，提升机房运维环境舒适性，解决噪声污染问题
- 液冷系统可以更高效地回收和再利用余热，有助于提升能源的总体利用效率
- 液冷服务器可以排除海拔、地域和气 温的差距，保证运行效率和性能，具备规模化应用的优势。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/c6290c440c9c31486781c45011396283.png)
相比于风冷有这么多优势，为什么没有在IDC 发展初期就大范围铺开，从IDC 的发展历史来看，初期，一台1U 的刀片服务器主要高密度计算还集中在逻辑控制任务，再到后来的互联网时代，思科的崛起，IDC 服务器主要处理的是路由转发任务，这两类任务的一个显著特点是还集中在逻辑判断和少量的计算，映射到芯片上的逻辑单元是ALU 和开关电路，从芯片的工作状态来说，这类计算相关的能量负载是非集中式的，同时能量开销也很低。因此负担这类计算所需要的散热需求也不是难么急切，大多状况下，IDC 中的服务器散热可能主要依赖几台挂式空调就好，部署难度极地，从IT 运维的收益来说，并没有动力去推动部署液冷。
![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/3ddd8bab804ff39e885f8b344dc0fa70.png)
从图中可以看到，芯片计算单元（MAC/ALU）小号的能量相比于DRAM数据搬运来说，小号的能量差了4个数量级，当下的智算中心所部署的服务器特点集中体现在高带宽（HBM/GDDR）,通常数据搬运的开销是整个网络执行的瓶颈所在。

### 液冷的护城河
回到液冷的讨论，当下的液冷解决方案供应商的技术护城河体现在哪里，为什么vrt 可以给到这么高的估值，并成为NV的唯一指定供应商。

目前主流的几种液冷方案：
| 液冷技术类型 | 描述                                                         |特点|
|--------------|--------------------------------------------------------------|---|
| 冷板式       | 将液冷冷板固定在服务器的主要发热器件上，依靠流经冷板的液体将热量带走达到散热目的。 |目前主流，占比超80%![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/eed5dc82a5d2a72611d9f51f68a31043.png)|
| 浸没式       | 将发热元件直接浸没在冷却液中，通过冷却液循环带走服务器等设备运行产生的热量。分类：单相、两相、直抵芯片             |未来大趋势![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/541140c7db0226a0a203a7b83c9bc58b.png)
|
| 喷淋式       | 在机箱顶部储液和开孔，根据发热体位置和发热量大小不同，让冷却液对发热体进行喷淋，达到设备冷却的目的。 ||




|关键技术|作用|详情  |
|--|--|---|
| 冷却液 |可用冷媒包括水、矿物油、电子氟化液等进行物理降温  |冷却液是关键的原材料之一。以前，冷却液基本上被3M为代表的国外企业垄断，如今国内企业在冷却液方面也取得了国产突破。巨化集团推出高性能巨芯专用冷却液,攻克了数据中心高效液冷与安全智能热控防护等关键技术，并实现批量生产。|
|连接器|通常是指液冷循环系统中各器件之间的连接件，它能 实现各器件之间的快速连接和断开且无泄漏，提高效率，减少排液注液带来的不必要的工作量。主 要应用于流体连接，可在带压状态下自由插拔且无泄漏。|液冷快速连接器的可靠性和绝对密封性至关重要，其事关整个液冷系统的安全性，使得其具备较高的技术门槛和较多的技术要点，包括防水密封、高耐用度及材质兼容性等|![在这里插入图片描述](https://img-blog.csdnimg.cn/direct/718358f3a00e4691951cd1ee8ae1b57b.png)|
|CDU（Cooling Dispensing Unit，冷却液分配单元|主要由机箱、水泵、板换、阀、膨胀罐以及 管路等等组成，通过板换进行热量交换，把冷却的液体送到热源处吸收热量，带着热量的液体再进 入板换进行换热处理，循环换热。|![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/1c3d1ea38ff2d61bf00f564a7bbe7542.png)|
|电磁阀|一般安装在连接的管道上控制冷媒流通。 |
|TANK|用于安装服务器/交换机的浸没式箱体，通过 tank 内的冷却介质直接对交换机进行散热|
|Manifold|分集水器，用于连接各路加热管供回水的配、集水装臵，按进、回水方式不同分为分 水器和集水器。|

国内已经形成了较为完整的液冷数据中心产业链，不过由于上游零部件的工艺性能、技术水平等方面与进口产品还是存在差距，液冷数据中心产业链有待完善。液冷技术非常复杂，涉及液冷数据中心系统架构层、液冷部件及接口层、液冷基础设施层（液冷机柜、组件、换热设备、室外集成冷源等）、液冷监控系统层等多方面，产业链上各个企业技术路径多种多样、产品规格千差万别，产品质量良莠不齐，让用户难以选择。

从业内的分析来看，目前产品的技术难点还在于连接器和冷却液以及配到的温控CDU 设备，但从行业发展规律看，这些技术难点相比于芯片，难度还是在可控范围内，国内迟早都可以突破，目前国内的技术发展还是有赖于产业的牵引，IDC 从风冷到液冷的坚定迁移（毕竟涉及到一次性的初期投入），才能保证液冷产业链的自身持续造血。
# 参考资料
- 液冷服务器行业专题研究：低碳之下，IDC“液冷时代”契机来临:https://new.qq.com/rain/a/20220923A02UQ100
- VRT 技术白皮书：https://www.vertiv.cn/498c95/globalassets/documents/white-papers/vertiv_data_center_liquid_cooling_solutions_white_paper_350067_0.pdf
- https://zhuanlan.zhihu.com/p/661617328
- https://xueqiu.com/3966435964/281902854
