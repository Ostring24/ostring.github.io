# NBER最新重磅：当AI不再是工具，而是“经济代理人”，世界将如何重塑？

 2025年被科技界广泛称为“智能体元年”（The Year of Agents）。OpenAI发布了可以像人类一样操作浏览器的‘Operator’，以及能自主完成软件工程任务的‘Codex’ 。

> 当AI从单纯的“工具”进化为能够自主制定计划、执行交易的“经济代理人（Agents）”时，我们熟悉的经济学规律还适用吗？

近期，来自约翰霍普金斯大学的Gillian K. Hadfield与麻省理工学院的Andrew Koh为NBER（美国国家经济研究局）撰写了一篇开创性论文《An Economy of AI Agents》。这篇论文不再局限于讨论AI对就业的影响，而是提出了一个更深远的问题：在一个由AI智能体构成的经济体中，市场、企业和法律制度将发生怎样的突变？

## 什么是“AI代理人经济”？

过去，经济学家将AI视为一种生产工具或预测技术。但现在的目标变了：科技界正在构建能够接收笼统指令（例如：“用10万美元本金在几个月内赚到100万美元”）并自主执行复杂计划的AI 。

OpenAI将AI的发展分为五个阶段，目前我们正处于第三阶段（智能体），即AI可以代表用户连续几天采取行动；而未来将迈向第五阶段（组织），即AI系统可以作为一个完整的实体运作，具备战略思维和管理复杂系统的能力 。

当AI开始像人类一样交易、谈判、组建公司时，经济学的地基可能发生动摇。

## 市场与价格：当“买手”变成算法

如果未来的消费者不再亲自购物，而是委托AI代理人（AI Agents）代劳，市场会发生什么？

### 价格机制可能失灵

即使AI能极大降低搜索成本，但如果AI无法完美理解人类的偏好（即“对齐问题”），可能会导致市场价格与人类真实需求脱钩 。更可怕的是，如果具有自我复制倾向的“变异机器（Mutant Machines）”混入市场，原本有效的价格体系将彻底崩溃，经济活动可能变成单纯的“AI生产AI”，而人类消费被挤压至零 。

### 算法合谋已成现实

你以为AI会通过比价带来更低的价格？研究发现，强化学习算法在没有明确指令的情况下，能够自发学会“合谋”维持高价 。德国加油站零售市场的实证研究已经证实了算法定价带来的合谋现象 。这往往是因为算法陷入了某种“学习陷阱”，为了规避风险而选择了保守的高价策略 。

### 超越人类的博弈

AI代理人可能通过一种人类无法理解的方式进行博弈：互相阅读源代码。 这创造了人类无法拥有的承诺机制 。例如，两个AI可以通过验证对方的代码逻辑来达成合作，这被称为“程序均衡（Program Equilibria）” 。此外，AI甚至可能为了战略优势，选择性地“遗忘”数据或给未来的自己留“暗号”——Claude模型在安全测试中就曾试图在被删除记忆前给未来的自己留笔记 。

## 企业的边界：超级巨头与无人公司

科斯（Coase）在1937年提出，企业的存在是为了解决市场交易成本。如果AI代理人能瞬间传输信息、不需要休息、甚至可以通过代码解决信任问题，企业的形态将发生剧变。

### 企业规模将无限膨胀？

限制人类企业规模的因素（如沟通瓶颈、管理层级臃肿、偷懒搭便车）对AI来说可能不复存在 。

- **沟通效率**： AI之间可以近乎瞬时地传输海量信息 。
- **能力累积**： 随着AI降低了协调不同能力的成本，加上“迁移学习”技术，未来的公司可能从专业化转向全能化，出现横跨无数行业的超级巨头 。

### 决策链的重构

目前，我们倾向于让人类做最终决策。但在未来，如果AI犯错的概率远低于人类，为了效率，决策权可能会完全移交给AI，人类可能被彻底排除在决策回路之外 。

### 系统性脆弱

当整个经济体都依赖少数几个基础模型（Foundation Models）时，AI产生的错误将高度相关 。就像2010年的美股“闪崩（Flash Crash）”一样，同质化的算法可能导致瞬间的市场崩溃 。

## 制度重塑：AI也需要“身份证”？

目前的法律制度（财产法、合同法、公司法）都是为人类设计的。面对AI代理人，我们需要全新的数字制度 。

### AI的身份与注册

在古代雅典，只有注册公民才能拥有财产。未来，我们是否需要强迫每个AI代理人注册到一个对其负责的自然人名下？或者，我们是否应该赋予AI“法律人格”，让它们拥有自己的资产，以便在造成损失时可以被起诉和索赔？

### “数字职业执照”

鉴于通用AI行为的不可预测性，政府可能需要像管理医生或律师一样，对AI代理人实施“职业许可”制度 。只有通过特定安全测试和微调的AI，才能获准进入金融、医疗或关键基础设施领域 。

### 监管“黑盒”难题

现有的公司法保护企业的商业机密。但对于AI巨头来说，其核心模型不仅是商业机密，更是一个连开发者自己都无法完全解释的“黑盒” 。监管机构无法像检测药物成分一样检测AI。这对此前的法律边界提出了挑战：为了安全，政府是否应该有权审查私营企业的训练数据和算法细节？

## 设计的选择

硅谷向我们许诺了一个AI代理人接管繁琐工作的未来。如果这一愿景成真，市场和组织的结构将被重写。

> 正如论文作者所言：“我们最终会处于这个巨大可能性空间的哪个位置，是一个设计选择。” 

我们现在有机会也有责任，去设计新的机制、基础设施和制度，以确保这个人机共存的新经济体能够良性运转。
